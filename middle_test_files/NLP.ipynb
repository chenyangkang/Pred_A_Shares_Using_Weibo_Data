{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /Users/chenyangkang/.cache/torch/sentence_transformers/uer_sbert-base-chinese-nli. Creating a new one with MEAN pooling.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "encoder = SentenceTransformer('uer/sbert-base-chinese-nli')\n",
    "# cyclone/simcse-chinese-roberta-wwm-ext\n",
    "# uer/sbert-base-chinese-nli \n",
    "# pe65374/xcoa-sbert-base-chinese-nli \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "### deal date\n",
    "def get_date(the_str):\n",
    "    months_dict = {\n",
    "            'jan': 1,\n",
    "            'feb': 2,\n",
    "            'mar': 3,\n",
    "            'apr':4,\n",
    "            'may':5,\n",
    "            'jun':6,\n",
    "            'jul':7,\n",
    "            'aug':8,\n",
    "            'sep':9,\n",
    "            'oct':10,\n",
    "            'nov':11,\n",
    "            'dec':12\n",
    "            }\n",
    "\n",
    "    date = the_str.split(' ')\n",
    "    month=months_dict[date[1].lower()]\n",
    "    day=date[2]\n",
    "    time=date[3]\n",
    "    year=date[5]\n",
    "    formatted_time = datetime.datetime.strptime(f'{year}-{str(month).zfill(2)}-{str(day).zfill(2)}-{time}','%Y-%m-%d-%H:%M:%S')\n",
    "    return formatted_time\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data_list = os.listdir('./Scrapped_weibo/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "88it [26:02, 17.76s/it] \n"
     ]
    }
   ],
   "source": [
    "#### strategy one: take mean of all influencers\n",
    "all_ = []\n",
    "for index,data_name in tqdm(enumerate(data_list),total=len(data_list)):\n",
    "    # if index<64:\n",
    "    #     continue\n",
    "    try:\n",
    "        data = pickle.load(open(f'./Scrapped_weibo/{data_name}','rb'))\n",
    "        name = data[0]['user_name']\n",
    "        dates =[ get_date(i['created_at']) for i in data]\n",
    "        text = [i['text'] for i in data]\n",
    "        res = encoder.encode(text)\n",
    "        responses = [i['reposts_count'] for i in data]\n",
    "        comments_count = [i['comments_count'] for i in data]\n",
    "        attitudes_count = [i['attitudes_count'] for i in data]\n",
    "        features = pd.DataFrame({\n",
    "            'date':dates,\n",
    "            'responses':responses,\n",
    "            'comments_count':comments_count,\n",
    "            'attitudes_count':attitudes_count,\n",
    "            'influencer':[name]*len(dates)\n",
    "        })\n",
    "\n",
    "        for i in range(res.shape[1]):\n",
    "            features[f's{i}']=res[:,i]\n",
    "\n",
    "        all_.append(features)\n",
    "    except Exception as e:\n",
    "        print(data_name,e)\n",
    "        continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.concat(all_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.to_csv('features.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 9:30 - 15:00 each day\n",
    "### only take 15:00 - 9:30 (next day) data into account\n",
    "### only data since 2018-01-01\n",
    "all_df['time'] = all_df.date.dt.time\n",
    "all_df['day'] = all_df.date.dt.date\n",
    "all_df['year'] = all_df.date.dt.year\n",
    "all_df['DOW'] = all_df.date.dt.day_of_week\n",
    "all_df = all_df[all_df.year>=2018]\n",
    "unique_date = sorted(all_df.date.dt.date.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_res = {}\n",
    "for date in unique_date:\n",
    "    DOW = pd.DataFrame([pd.to_datetime(date)])[0].dt.day_of_week.values[0]\n",
    "    if DOW==1:\n",
    "        sub=all_df[(all_df.date>=datetime.datetime.strptime(\n",
    "            str(date-datetime.timedelta(days=2))+'-15:00:00', '%Y-%m-%d-%H:%M:%S'\n",
    "            )) & (all_df.date<=datetime.datetime.strptime(\n",
    "            str(date)+'-9:00:00', '%Y-%m-%d-%H:%M:%S'\n",
    "                ))\n",
    "                ]\n",
    "    else:\n",
    "        sub=all_df[(all_df.date>=datetime.datetime.strptime(\n",
    "        str(date-datetime.timedelta(days=1))+'-15:00:00', '%Y-%m-%d-%H:%M:%S'\n",
    "        )) & (all_df.date<=datetime.datetime.strptime(\n",
    "        str(date)+'-9:00:00', '%Y-%m-%d-%H:%M:%S'\n",
    "            ))\n",
    "            ]\n",
    "\n",
    "    if len(sub)<5:\n",
    "        continue\n",
    "    if len(sub.influencer.unique())<5:\n",
    "        continue\n",
    "\n",
    "    mean_features = sub.groupby('influencer').mean()\n",
    "    ind_count = mean_features.shape[0]\n",
    "    mean_mean_features = mean_features[[f's{i}' for i in range(0,768)]].mean(axis=0)\n",
    "\n",
    "    mean_mean_features={\n",
    "        **{'ind_count':ind_count},\n",
    "        **dict(mean_mean_features)\n",
    "\n",
    "    }\n",
    "\n",
    "    mean_res[date] = mean_mean_features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mean_features = pd.DataFrame(mean_res).T.reset_index(drop=False).rename(columns={'index':'date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mean_features.to_csv('mean_features.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e9867b585c0f10e2eb480253e40cab44b53d9f15cdd7fb9c79b17a5cb2fa039"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
